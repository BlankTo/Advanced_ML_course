{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "\n",
    "import tarfile\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import VisionDataset\n",
    "from torchvision.models import alexnet\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from torch.backends import cudnn\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tarfile.open('caltech-101/101_ObjectCategories.tar.gz', 'r:gz') as tar_f:\n",
    "#    tar_f.extractall('data/')\n",
    "#\n",
    "#with tarfile.open('caltech-101/Annotations.tar', 'r:') as tar_f:\n",
    "#    tar_f.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "def create_label_dict(labels):\n",
    "\n",
    "    label_to_int = {}\n",
    "    int_to_label = {}\n",
    "    label_set = sorted(list(set(labels)), key= lambda x: x.lower())\n",
    "\n",
    "    for i, l in enumerate(label_set):\n",
    "\n",
    "            label_to_int[l] = i\n",
    "            int_to_label[i] = l\n",
    "    \n",
    "    return label_to_int, int_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Caltech(VisionDataset):\n",
    "    def __init__(self, root, split='train', background_class= False, data_augmentation= None, transform=None, target_transform=None):\n",
    "        super(Caltech, self).__init__(root, transform=transform, target_transform=target_transform)\n",
    "\n",
    "        self.split = split\n",
    "\n",
    "        self.images = []\n",
    "        self.str_labels = []\n",
    "\n",
    "        split_path = 'train.txt' if split == 'train' else 'test.txt'\n",
    "\n",
    "        with open(split_path, 'r') as f:\n",
    "            for line in f:\n",
    "                cat = line.split('/')[0]\n",
    "                if background_class or cat != 'BACKGROUND_Google':\n",
    "                    self.images.append(pil_loader('data/101_ObjectCategories/' + line.strip('\\n')))\n",
    "                    self.str_labels.append(cat)\n",
    "        \n",
    "        self.label_to_int, self.int_to_label = create_label_dict(self.str_labels)\n",
    "\n",
    "        self.labels = [self.label_to_int[l] for l in self.str_labels]\n",
    "\n",
    "        if data_augmentation is not None:\n",
    "            new_images = []\n",
    "            new_labels = []\n",
    "\n",
    "            for im, lab in zip(self.images, self.labels):\n",
    "                \n",
    "                new_images.append(im)\n",
    "                new_labels.append(lab)\n",
    "\n",
    "                if 'hflip' in data_augmentation:\n",
    "                    new_images.append(im.transpose(Image.FLIP_LEFT_RIGHT))\n",
    "                    new_labels.append(lab)\n",
    "\n",
    "                if 'vflip' in data_augmentation:\n",
    "                    new_images.append(im.transpose(Image.FLIP_TOP_BOTTOM))\n",
    "                    new_labels.append(lab)\n",
    "\n",
    "                if 'bflip' in data_augmentation:\n",
    "                    new_images.append(im.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM))\n",
    "                    new_labels.append(lab)\n",
    "\n",
    "                if 'bright' in data_augmentation:\n",
    "                    enhancer = ImageEnhance.Brightness(im)\n",
    "                    new_images.append(enhancer.enhance(1.5))\n",
    "                    new_labels.append(lab)\n",
    "\n",
    "                if 'blur' in data_augmentation:\n",
    "                    new_images.append(im.filter(ImageFilter.BLUR))\n",
    "                    new_labels.append(lab)\n",
    "\n",
    "            self.images = new_images\n",
    "            self.labels = new_labels\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self): return len(self.labels)\n",
    "\n",
    "    def get_label(self, index): return self.int_to_label[index]\n",
    "\n",
    "    def info(self): print(f'{self.split} set - N: {len(self.labels)} - L: {len(self.label_to_int)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                      transforms.Resize(256),      # Resizes short size of the PIL image to 256\n",
    "                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n",
    "                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n",
    "                                                                   # Remember this when applying different transformations, otherwise you get an error\n",
    "                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                                      #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),# Normalizes tensor with mean and standard deviation\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                      ])\n",
    "# Define transforms for the evaluation phase\n",
    "eval_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DS = Caltech('', split= 'train', background_class= False, transform= train_transform)\n",
    "#train_DS = Caltech('', split= 'train', background_class= False, data_augmentation= ['bright'], transform= train_transform)\n",
    "\n",
    "\n",
    "test_dataset = Caltech('', split= 'test', background_class= False, transform= eval_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5784\n",
      "0\n",
      "accordion\n",
      "5\n",
      "train set - N: 5784 - L: 101\n"
     ]
    }
   ],
   "source": [
    "print(len(train_DS))\n",
    "print(train_DS[0][1])\n",
    "print(train_DS.int_to_label[train_DS[0][1]])\n",
    "print(train_DS.label_to_int['bass'])\n",
    "train_DS.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: 4269\n",
      "Valid Dataset: 1475\n",
      "Test Dataset: 2893\n"
     ]
    }
   ],
   "source": [
    "train_indexes = [] # split the indices for your train split\n",
    "val_indexes = []# split the indices for your val split\n",
    "c = train_DS[0][1]\n",
    "tmp_idx = [0]\n",
    "for i in range(1, len(train_DS)):\n",
    "    if train_DS[i][1] == c: tmp_idx.append(i)\n",
    "    else:\n",
    "        for cc in tmp_idx[:-ceil(len(tmp_idx)/4)]: train_indexes.append(cc)\n",
    "        for cc in tmp_idx[-ceil(len(tmp_idx)/4):]: val_indexes.append(cc)\n",
    "        c = train_DS[i][1]\n",
    "        tmp_idx = [i]\n",
    "\n",
    "train_dataset = Subset(train_DS, train_indexes)\n",
    "val_dataset = Subset(train_DS, val_indexes)\n",
    "\n",
    "print('Train Dataset: {}'.format(len(train_dataset)))\n",
    "print('Valid Dataset: {}'.format(len(val_dataset)))\n",
    "print('Test Dataset: {}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "LR = 1e-2\n",
    "\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "WEIGHT_DECAY = 5e-5\n",
    "\n",
    "STEP_SIZE = 20\n",
    "GAMMA = 0.1\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "LOG_FREQUENCY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = alexnet(weights= 'AlexNet_Weights.DEFAULT')\n",
    "\n",
    "net.classifier[6] = nn.Linear(4096, len(train_DS.label_to_int))\n",
    "\n",
    "for param in net.features[:6].parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "parameters_to_optimize = net.parameters()\n",
    "\n",
    "optimizer = opt.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "#optimizer = opt.Adam(parameters_to_optimize, lr = LR)\n",
    "\n",
    "scheduler = opt.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Number of CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "\n",
    "num_cuda_devices = torch.cuda.device_count()\n",
    "\n",
    "print(f\"Number of CUDA devices: {num_cuda_devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/50, LR = [0.01]\n",
      "Step 0, Loss 4.970935344696045\n",
      "Step 10, Loss 2.001197576522827\n",
      "Starting epoch 2/50, LR = [0.01]\n",
      "Step 20, Loss 0.5509081482887268\n",
      "Step 30, Loss 0.5933026671409607\n",
      "Starting epoch 3/50, LR = [0.01]\n",
      "Step 40, Loss 0.21035802364349365\n",
      "Starting epoch 4/50, LR = [0.01]\n",
      "Step 50, Loss 0.11951594799757004\n",
      "Step 60, Loss 0.17377467453479767\n",
      "Starting epoch 5/50, LR = [0.01]\n",
      "Step 70, Loss 0.07937077432870865\n",
      "Starting epoch 6/50, LR = [0.01]\n",
      "Step 80, Loss 0.0742347314953804\n",
      "Step 90, Loss 0.061456214636564255\n",
      "Starting epoch 7/50, LR = [0.01]\n",
      "Step 100, Loss 0.024531280621886253\n",
      "Step 110, Loss 0.030192948877811432\n",
      "Starting epoch 8/50, LR = [0.01]\n",
      "Step 120, Loss 0.03307405486702919\n",
      "Starting epoch 9/50, LR = [0.01]\n",
      "Step 130, Loss 0.04904419183731079\n",
      "Step 140, Loss 0.07566511631011963\n",
      "Starting epoch 10/50, LR = [0.01]\n",
      "Step 150, Loss 0.04333600029349327\n",
      "Starting epoch 11/50, LR = [0.01]\n",
      "Step 160, Loss 0.027896180748939514\n",
      "Step 170, Loss 0.012101756408810616\n",
      "Starting epoch 12/50, LR = [0.01]\n",
      "Step 180, Loss 0.011880969628691673\n",
      "Step 190, Loss 0.025800490751862526\n",
      "Starting epoch 13/50, LR = [0.01]\n",
      "Step 200, Loss 0.0075694480910897255\n",
      "Starting epoch 14/50, LR = [0.01]\n",
      "Step 210, Loss 0.008973921649158001\n",
      "Step 220, Loss 0.027401424944400787\n",
      "Starting epoch 15/50, LR = [0.01]\n",
      "Step 230, Loss 0.007909121923148632\n",
      "Starting epoch 16/50, LR = [0.01]\n",
      "Step 240, Loss 0.026603547856211662\n",
      "Step 250, Loss 0.03231683745980263\n",
      "Starting epoch 17/50, LR = [0.01]\n",
      "Step 260, Loss 0.007918471470475197\n",
      "Step 270, Loss 0.008911149576306343\n",
      "Starting epoch 18/50, LR = [0.01]\n",
      "Step 280, Loss 0.016322268173098564\n",
      "Starting epoch 19/50, LR = [0.01]\n",
      "Step 290, Loss 0.008444543927907944\n",
      "Step 300, Loss 0.0036312639713287354\n",
      "Starting epoch 20/50, LR = [0.01]\n",
      "Step 310, Loss 0.006823235657066107\n",
      "Starting epoch 21/50, LR = [0.001]\n",
      "Step 320, Loss 0.006292469333857298\n",
      "Step 330, Loss 0.004807178396731615\n",
      "Starting epoch 22/50, LR = [0.001]\n",
      "Step 340, Loss 0.007484072353690863\n",
      "Step 350, Loss 0.0015789431054145098\n",
      "Starting epoch 23/50, LR = [0.001]\n",
      "Step 360, Loss 0.009537145495414734\n",
      "Starting epoch 24/50, LR = [0.001]\n",
      "Step 370, Loss 0.0055197300389409065\n",
      "Step 380, Loss 0.0016310462960973382\n",
      "Starting epoch 25/50, LR = [0.001]\n",
      "Step 390, Loss 0.007186156697571278\n",
      "Starting epoch 26/50, LR = [0.001]\n",
      "Step 400, Loss 0.0010009828256443143\n",
      "Step 410, Loss 0.0031473736744374037\n",
      "Starting epoch 27/50, LR = [0.001]\n",
      "Step 420, Loss 0.0013437132583931088\n",
      "Step 430, Loss 0.006346066948026419\n",
      "Starting epoch 28/50, LR = [0.001]\n",
      "Step 440, Loss 0.0024550145026296377\n",
      "Starting epoch 29/50, LR = [0.001]\n",
      "Step 450, Loss 0.0022062098141759634\n",
      "Step 460, Loss 0.0009431076468899846\n",
      "Starting epoch 30/50, LR = [0.001]\n",
      "Step 470, Loss 0.001529951929114759\n",
      "Starting epoch 31/50, LR = [0.001]\n",
      "Step 480, Loss 0.006914206780493259\n",
      "Step 490, Loss 0.002237466396763921\n",
      "Starting epoch 32/50, LR = [0.001]\n",
      "Step 500, Loss 0.003434940008446574\n",
      "Step 510, Loss 0.010271928273141384\n",
      "Starting epoch 33/50, LR = [0.001]\n",
      "Step 520, Loss 0.010189974680542946\n",
      "Starting epoch 34/50, LR = [0.001]\n",
      "Step 530, Loss 0.0028725096490234137\n",
      "Step 540, Loss 0.0037169030401855707\n",
      "Starting epoch 35/50, LR = [0.001]\n",
      "Step 550, Loss 0.01515799481421709\n",
      "Starting epoch 36/50, LR = [0.001]\n",
      "Step 560, Loss 0.004434026312083006\n",
      "Step 570, Loss 0.001871308428235352\n",
      "Starting epoch 37/50, LR = [0.001]\n",
      "Step 580, Loss 0.0016706452006474137\n",
      "Step 590, Loss 0.001563795143738389\n",
      "Starting epoch 38/50, LR = [0.001]\n",
      "Step 600, Loss 0.001483291038312018\n",
      "Starting epoch 39/50, LR = [0.001]\n",
      "Step 610, Loss 0.0015880995197221637\n",
      "Step 620, Loss 0.00396066065877676\n",
      "Starting epoch 40/50, LR = [0.001]\n",
      "Step 630, Loss 0.0026327248197048903\n",
      "Starting epoch 41/50, LR = [0.0001]\n",
      "Step 640, Loss 0.0007844804204069078\n",
      "Step 650, Loss 0.007416354492306709\n",
      "Starting epoch 42/50, LR = [0.0001]\n",
      "Step 660, Loss 0.0025145551189780235\n",
      "Step 670, Loss 0.0009408447076566517\n",
      "Starting epoch 43/50, LR = [0.0001]\n",
      "Step 680, Loss 0.0011103677097707987\n",
      "Starting epoch 44/50, LR = [0.0001]\n",
      "Step 690, Loss 0.01419779658317566\n",
      "Step 700, Loss 0.0020670092198997736\n",
      "Starting epoch 45/50, LR = [0.0001]\n",
      "Step 710, Loss 0.001861613942310214\n",
      "Starting epoch 46/50, LR = [0.0001]\n",
      "Step 720, Loss 0.00046418432611972094\n",
      "Step 730, Loss 0.0025916658341884613\n",
      "Starting epoch 47/50, LR = [0.0001]\n",
      "Step 740, Loss 0.0008501795819029212\n",
      "Step 750, Loss 0.0012852555373683572\n",
      "Starting epoch 48/50, LR = [0.0001]\n",
      "Step 760, Loss 0.0037051800172775984\n",
      "Starting epoch 49/50, LR = [0.0001]\n",
      "Step 770, Loss 0.0030820246320217848\n",
      "Step 780, Loss 0.0011489351745694876\n",
      "Starting epoch 50/50, LR = [0.0001]\n",
      "Step 790, Loss 0.008868367411196232\n"
     ]
    }
   ],
   "source": [
    "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
    "\n",
    "cudnn.benchmark # Calling this optimizes runtime\n",
    "\n",
    "current_step = 0\n",
    "# Start iterating over the epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_last_lr()))\n",
    "\n",
    "  # Iterate over the dataset\n",
    "  for images, labels in train_dataloader:\n",
    "    # Bring data over the device of choice\n",
    "    images = images.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    net.train() # Sets module in training mode\n",
    "\n",
    "    # PyTorch, by default, accumulates gradients after each backward pass\n",
    "    # We need to manually set the gradients to zero before starting a new iteration\n",
    "    optimizer.zero_grad() # Zero-ing the gradients\n",
    "\n",
    "    # Forward pass to the network\n",
    "    outputs = net(images)\n",
    "\n",
    "    # Compute loss based on output and ground truth\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Log loss\n",
    "    if current_step % LOG_FREQUENCY == 0:\n",
    "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
    "\n",
    "    # Compute gradients for each layer and update weights\n",
    "    loss.backward()  # backward pass: computes gradients\n",
    "    optimizer.step() # update weights based on accumulated gradients\n",
    "\n",
    "    current_step += 1\n",
    "\n",
    "  # Step the scheduler\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.856271186440678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
    "net.train(False) # Set Network to evaluation mode\n",
    "\n",
    "running_corrects = 0\n",
    "for images, labels in tqdm(val_dataloader):\n",
    "  images = images.to(DEVICE)\n",
    "  labels = labels.to(DEVICE)\n",
    "\n",
    "  # Forward Pass\n",
    "  outputs = net(images)\n",
    "\n",
    "  # Get predictions\n",
    "  _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "  # Update Corrects\n",
    "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = running_corrects / float(len(val_dataset))\n",
    "\n",
    "print('Validation Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:06<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8606982371240927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
    "net.train(False) # Set Network to evaluation mode\n",
    "\n",
    "running_corrects = 0\n",
    "for images, labels in tqdm(test_dataloader):\n",
    "  images = images.to(DEVICE)\n",
    "  labels = labels.to(DEVICE)\n",
    "\n",
    "  # Forward Pass\n",
    "  outputs = net(images)\n",
    "\n",
    "  # Get predictions\n",
    "  _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "  # Update Corrects\n",
    "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = running_corrects / float(len(test_dataset))\n",
    "\n",
    "print('Test Accuracy: {}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
