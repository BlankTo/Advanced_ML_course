{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_Zm_LPoFdE5"
      },
      "source": [
        "**DOWNLOAD THE PACS DATASET & SETUP THE ENVIRONMENT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o19xJiPGC_1t"
      },
      "outputs": [],
      "source": [
        "## Download PACS Dataset Images\n",
        "#!git clone https://github.com/MachineLearning2020/Homework3-PACS/\n",
        "#!mv Homework3-PACS/PACS/ .\n",
        "#!rm -r Homework3-PACS/\n",
        "#\n",
        "## Download PACS Dataset Labels\n",
        "#!git clone https://github.com/silvia1993/DANN_Template/\n",
        "#!mv DANN_Template/txt_lists/art_painting.txt PACS/\n",
        "#!mv DANN_Template/txt_lists/cartoon.txt PACS/\n",
        "#!mv DANN_Template/txt_lists/photo.txt PACS/\n",
        "#!mv DANN_Template/txt_lists/sketch.txt PACS/\n",
        "#!rm -r DANN_Template/\n",
        "#\n",
        "## Install additional libraries\n",
        "#!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BHbLv49Hm8u"
      },
      "source": [
        "**GLOBAL VARIABLES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5cnkqXhaHMGt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as opt\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "NUM_CLASSES = 7\n",
        "BATCH_SIZE = 256\n",
        "LR = 1e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrg-Ss56IZX9"
      },
      "source": [
        "**DATASET MANAGEMENT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "mNB5VstJIcYf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "import os\n",
        "\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "\n",
        "from math import ceil\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "    \n",
        "def create_label_dict(labels):\n",
        "\n",
        "    label_to_int = {}\n",
        "    int_to_label = {}\n",
        "    label_set = sorted(list(set(labels)), key= lambda x: x.lower())\n",
        "\n",
        "    for i, l in enumerate(label_set):\n",
        "\n",
        "            label_to_int[l] = i\n",
        "            int_to_label[i] = l\n",
        "    \n",
        "    return label_to_int, int_to_label\n",
        "\n",
        "# Define the Dataset class\n",
        "class PACSDataset(Dataset):\n",
        "    def __init__(self, split= 'train', transform= None, target_transform= None):\n",
        "        super(PACSDataset, self).__init__()\n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.split = split\n",
        "\n",
        "        self.images = []\n",
        "        self.str_labels = []\n",
        "        self.domains = []\n",
        "\n",
        "\n",
        "        for dom in ['cartoon', 'sketch']:\n",
        "            #print(dom)\n",
        "\n",
        "            for cat in os.listdir('PACS/kfold/' + dom + '/'):\n",
        "                #print(cat)\n",
        "                ims = []\n",
        "                labs = []\n",
        "                doms = []\n",
        "                for image in os.listdir('PACS/kfold/' + dom + '/' + cat + '/'):\n",
        "                    ims.append(pil_loader('PACS/kfold/' + dom + '/' + cat + '/' + image))\n",
        "                    labs.append(cat)\n",
        "                    doms.append(0 if dom == 'cartoon' else 1)\n",
        "                \n",
        "                rangei = range(ceil(len(ims) * 3 / 4)) if self.split == 'train' else range(ceil(len(ims) * 3 / 4), len(ims))\n",
        "                for i in rangei:\n",
        "                    self.images.append(ims[i])\n",
        "                    self.str_labels.append(labs[i])\n",
        "                    self.domains.append(doms[i])\n",
        "\n",
        "                #for image in os.listdir('PACS/kfold/' + dom + '/' + cat + '/'):\n",
        "                #    #print(ima)\n",
        "                #    self.images.append(pil_loader('PACS/kfold/' + dom + '/' + cat + '/' + image))\n",
        "                #    self.str_labels.append(cat)\n",
        "                #    self.domains.append(0 if dom == 'cartoon' else 1)\n",
        "\n",
        "        self.label_to_int, self.int_to_label = create_label_dict(self.str_labels)\n",
        "        self.labels = [self.label_to_int[l] for l in self.str_labels]\n",
        "\n",
        "    def __len__(self): return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        image = self.images[index]\n",
        "        label = self.labels[index]\n",
        "        domain = self.domains[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, domain\n",
        "    \n",
        "train_DS = PACSDataset(split= 'train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWeVJrW2NiFM"
      },
      "source": [
        "**ARCHITECTURE SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "GB1UGpoSJL4w"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "import torchvision.models as models\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None\n",
        "\n",
        "# Define AlexNet architecture class\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000, num_domains= 4):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        self.pretrained_alexnet = models.alexnet(pretrained=True)\n",
        "        self.pretrained_alexnet.classifier = nn.Sequential(*list(self.pretrained_alexnet.classifier.children())[:-1])\n",
        "        self.new_classifier = nn.Linear(4096, num_classes)\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        )\n",
        "        # Category classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "        # Domain classifier\n",
        "        #...\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 1000),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1000, 1000),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1000, num_domains)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, alpha= None):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "        class_outputs = self.classifier(features)\n",
        "\n",
        "        #...\n",
        "        domain_output = None\n",
        "        if alpha is not None:\n",
        "            reverse_features = ReverseLayerF.apply(features, alpha)\n",
        "            domain_output = self.domain_classifier(reverse_features)\n",
        "\n",
        "        return class_outputs, domain_output\n",
        "    \n",
        "    def predict_class(self, x):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "\n",
        "        # Domain classification branch (no gradient reversal layer during testing)\n",
        "        class_output = self.classifier(features)\n",
        "\n",
        "        return class_output\n",
        "    \n",
        "    def predict_domain(self, x):\n",
        "        features = self.features(x)\n",
        "        features = features.view(features.size(0), -1)\n",
        "\n",
        "        # Domain classification branch (no gradient reversal layer during testing)\n",
        "        domain_output = self.domain_classifier(features)\n",
        "\n",
        "        return domain_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFs2aJrQUjTd"
      },
      "source": [
        "**OPTIMIZATION LOOP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "qpS7tvk7OaPF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting epoch 1/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 0, Loss 3.329279899597168\n",
            "Step 10, Loss 3.3061351776123047\n",
            "Starting epoch 2/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 20, Loss 3.265162229537964\n",
            "Step 30, Loss 3.2161917686462402\n",
            "Starting epoch 3/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 40, Loss 3.1619884967803955\n",
            "Step 50, Loss 3.11891508102417\n",
            "Starting epoch 4/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 60, Loss 3.0480637550354004\n",
            "Step 70, Loss 2.980602264404297\n",
            "Starting epoch 5/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 80, Loss 2.9236109256744385\n",
            "Starting epoch 6/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 90, Loss 2.893913745880127\n",
            "Step 100, Loss 2.794426202774048\n",
            "Starting epoch 7/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 110, Loss 2.7078022956848145\n",
            "Step 120, Loss 2.6939802169799805\n",
            "Starting epoch 8/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 130, Loss 2.6459264755249023\n",
            "Step 140, Loss 2.540217161178589\n",
            "Starting epoch 9/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 150, Loss 2.5428316593170166\n",
            "Step 160, Loss 2.496501922607422\n",
            "Starting epoch 10/30, LR = [0.001, 0.001, 0.001]\n",
            "Step 170, Loss 2.558401584625244\n",
            "Starting epoch 11/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 180, Loss 2.501715898513794\n",
            "Step 190, Loss 2.517984628677368\n",
            "Starting epoch 12/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 200, Loss 2.477479934692383\n",
            "Step 210, Loss 2.560994863510132\n",
            "Starting epoch 13/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 220, Loss 2.5372936725616455\n",
            "Step 230, Loss 2.454843282699585\n",
            "Starting epoch 14/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 240, Loss 2.504106283187866\n",
            "Step 250, Loss 2.5922141075134277\n",
            "Starting epoch 15/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 260, Loss 2.4641072750091553\n",
            "Starting epoch 16/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 270, Loss 2.511235237121582\n",
            "Step 280, Loss 2.5039124488830566\n",
            "Starting epoch 17/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 290, Loss 2.49348521232605\n",
            "Step 300, Loss 2.4627342224121094\n",
            "Starting epoch 18/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 310, Loss 2.5070137977600098\n",
            "Step 320, Loss 2.477247476577759\n",
            "Starting epoch 19/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 330, Loss 2.5288686752319336\n",
            "Step 340, Loss 2.5248429775238037\n",
            "Starting epoch 20/30, LR = [0.0001, 0.0001, 0.0001]\n",
            "Step 350, Loss 2.528047561645508\n",
            "Starting epoch 21/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 360, Loss 2.527012348175049\n",
            "Step 370, Loss 2.4581141471862793\n",
            "Starting epoch 22/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 380, Loss 2.4825632572174072\n",
            "Step 390, Loss 2.5063788890838623\n",
            "Starting epoch 23/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 400, Loss 2.480020046234131\n",
            "Step 410, Loss 2.528122901916504\n",
            "Starting epoch 24/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 420, Loss 2.5107946395874023\n",
            "Step 430, Loss 2.5544657707214355\n",
            "Starting epoch 25/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 440, Loss 2.433648109436035\n",
            "Starting epoch 26/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 450, Loss 2.4663894176483154\n",
            "Step 460, Loss 2.503051519393921\n",
            "Starting epoch 27/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 470, Loss 2.5214619636535645\n",
            "Step 480, Loss 2.5074169635772705\n",
            "Starting epoch 28/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 490, Loss 2.492649793624878\n",
            "Step 500, Loss 2.488466262817383\n",
            "Starting epoch 29/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 510, Loss 2.5378520488739014\n",
            "Step 520, Loss 2.499582290649414\n",
            "Starting epoch 30/30, LR = [1e-05, 1e-05, 1e-05]\n",
            "Step 530, Loss 2.501429796218872\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models import AlexNet_Weights\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy\n",
        "import torchvision.models as models\n",
        "\n",
        "#### DATA SETUP\n",
        "# Define the transforms to use on images\n",
        "dataset_transform = T.Compose([\n",
        "    T.Resize(256),\n",
        "    T.CenterCrop(224),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define the Dataset object for training & testing\n",
        "train_dataset = PACSDataset(split= 'train', transform= dataset_transform)\n",
        "test_dataset = PACSDataset(split= 'test', transform= dataset_transform)\n",
        "\n",
        "# Define the DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "#### ARCHITECTURE SETUP\n",
        "# Create the Network Architecture object\n",
        "model = AlexNet(num_classes= 7)\n",
        "# Load pre-trained weights\n",
        "#model.load_state_dict(pretrained_alexnet.state_dict()).....\n",
        "# Overwrite the final classifier layer as we only have 7 classes in PACS\n",
        "#model.classifier[-1] = nn.Linear(4096, 7).....\n",
        "\n",
        "criterion_class = nn.CrossEntropyLoss()\n",
        "criterion_domain = nn.CrossEntropyLoss()\n",
        "\n",
        "#### TRAINING SETUP\n",
        "# Move model to device before passing it to the optimizer\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "# Create Optimizer & Scheduler objects\n",
        "optimizer = opt.SGD([\n",
        "    {'params': model.features.parameters()},\n",
        "    {'params': model.classifier.parameters()},\n",
        "    {'params': model.domain_classifier.parameters()}\n",
        "], lr=0.001, momentum=0.9)\n",
        "scheduler = opt.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "\n",
        "#### TRAINING LOOP\n",
        "#... for epoch in range(NUM_EPOCHS)...\n",
        "current_step = 0\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_last_lr()))\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  for images, labels, domain_labels in train_dataloader:\n",
        "    # Bring data over the device of choice\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "    domain_labels = domain_labels.to(DEVICE)\n",
        "\n",
        "    model.train() # Sets module in training mode\n",
        "\n",
        "    # PyTorch, by default, accumulates gradients after each backward pass\n",
        "    # We need to manually set the gradients to zero before starting a new iteration\n",
        "    optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "    # Forward pass to the network\n",
        "    class_outputs, domain_outputs = model(images, alpha= 0.1)\n",
        "\n",
        "    # Compute loss based on output and ground truth\n",
        "    class_loss = criterion_class(class_outputs, labels)\n",
        "    domain_loss = criterion_domain(domain_outputs, domain_labels)\n",
        "\n",
        "    total_loss = class_loss + domain_loss\n",
        "\n",
        "    # Log loss\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, total_loss.item()))\n",
        "\n",
        "    # Compute gradients for each layer and update weights\n",
        "    total_loss.backward()  # backward pass: computes gradients\n",
        "    optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "    current_step += 1\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:03<00:00,  2.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.6270753512132823\n",
            "\n",
            "Accuracy on the target domain: 62.71%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "#### TEST LOOP\n",
        "#...\n",
        "model = model.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "model.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels, domain in tqdm(test_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "  domain = domain.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  #class_outputs, domain_outputs = model(images)\n",
        "  domain_outputs = model.predict_domain(images)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(domain_outputs, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == domain).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))\n",
        "\n",
        "print(f'\\nAccuracy on the target domain: {100 * accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:02<00:00,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.22541507024265645\n",
            "\n",
            "Accuracy on the target domain: 22.54%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "#### TEST LOOP\n",
        "#...\n",
        "model = model.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "model.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels, domain in tqdm(test_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "  domain = domain.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  #class_outputs, domain_outputs = model(images)\n",
        "  class_outputs = model.predict_class(images)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(class_outputs, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(test_dataset))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))\n",
        "\n",
        "print(f'\\nAccuracy on the target domain: {100 * accuracy:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
